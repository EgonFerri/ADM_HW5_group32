{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Visit the Wikipedia hyperlinks graph!\n",
    "In this assignment we perform an analysis of the Wikipedia Hyperlink graph. In particular, given extra information about the categories to which an article belongs to, we are curious to rank the articles according to some criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from heapq import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research questions\n",
    "\n",
    "\n",
    "### **[RQ1]** \n",
    "Build the graph <img src=\"https://latex.codecogs.com/gif.latex?G=(V,&space;E)\" title=\"G=(V, E)\" /> where *V* is the set of articles and *E* the hyperlinks among them, and provide its basic information:\n",
    " \n",
    "- If it is direct or not\n",
    "- The number of nodes\n",
    "- The number of edges \n",
    "- The average node degree. Is the graph dense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty row\n"
     ]
    }
   ],
   "source": [
    "F = open('wiki-topcats-reduced.txt','r') \n",
    "rows=F.read().split('\\n') #split the rows\n",
    "grafo={}#initialize the graph\n",
    "reciver_nodes=set()\n",
    "for row in rows:\n",
    "        link=row.split('\\t') \n",
    "        if link[0] not in grafo: #add the vertex if it doesn't exist\n",
    "            try:\n",
    "                grafo[link[0]]=set()\n",
    "                grafo[link[0]].add(link[1]) #add the edge\n",
    "                reciver_nodes.add(link[1])\n",
    "            except: print('empty row')\n",
    "        else:\n",
    "            grafo[link[0]].add(link[1])\n",
    "            reciver_nodes.add(link[1])\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyreciver=(reciver_nodes-set(grafo.keys()))\n",
    "for node in onlyreciver:\n",
    "    grafo[node]=set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Find out if it's directed or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for neighbors in grafo['52']:\n",
    "    print('52' in grafo[neighbors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it's directed, since we have unspecular edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the number of nodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461194"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes=len(grafo)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the number of edges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges=0\n",
    "for node in grafo:\n",
    "    try: edges+=(len(grafo[node]))\n",
    "    except: pass\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the average node degree. Is the graph dense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In graph theory, the degree of a vertex of a graph is the number of edges incident to the vertex. The degree of a vertex $v$ is denoted $\\deg(v)$.\n",
    "\n",
    "The average degree is denoted as $\\frac{E}{N}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.735649206190887"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_degree= edges/nodes\n",
    "avg_degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the average node degree is slightly great than six.\n",
    "In mathematics, a dense graph is a graph in which the number of edges is close to the maximal number of edges.\n",
    "Looking at our numbers, we can immediatly say that the graph is not dense, but very sparse.\n",
    "\n",
    "To have a matematical confirm of this we can compute the density as $D={\\frac{|E|}{|N|\\,(|N|-1)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2436548703451455e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density = edges/(nodes*(nodes-1))\n",
    "density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis is verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness we create a dictionary that maps every page with it's name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open('wiki-topcats-page-names.txt','r')\n",
    "articles={}\n",
    "for line in F.readlines():\n",
    "    num=line.split()[0]\n",
    "    tit=line.split()[1:]\n",
    "    title=' '.join(tit)\n",
    "    articles[num]=title\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[RQ2]** \n",
    "Given a category <img src=\"https://latex.codecogs.com/gif.latex?C_0&space;=&space;\\{article_1,&space;article_2,&space;\\dots&space;\\}\" title=\"C_0 = \\{article_1, article_2, \\dots \\}\" /> as input we want to rank all of the nodes in *V* according to the following criteria:\n",
    "\t\n",
    "* Obtain a *block-ranking*, where the blocks are represented by the categories. In particular, we want:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?block_{RANKING}&space;=\\begin{bmatrix}&space;C_0&space;\\\\&space;C_1&space;\\\\&space;\\dots&space;\\\\&space;C_c\\\\&space;\\end{bmatrix}\" title=\"block_{RANKING} =\\begin{bmatrix} C_0 \\\\ C_1 \\\\ \\dots \\\\ C_c\\\\ \\end{bmatrix}\" />\n",
    "\t\n",
    "Each category $C_i$ corresponds to a list of nodes. \n",
    "\n",
    "The first category of the rank, $C_0$, always corresponds to the input category. The order of the remaining categories is given by:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?$$distance(C_0,&space;C_i)&space;=&space;median(ShortestPath(C_0,&space;C_i))$$\" title=\"distance(C_0, C_i) = median(ShortestPath(C_0, C_i))\" />\n",
    "\n",
    "The lower is the distance from $C_0$, the higher is the $C_i$ position in the rank. $ShortestPath(C_0, C_i)$ is the set of all the possible shortest paths between the nodes of $C_0$  and $C_i$. Moreover, the length of a path is given by the sum of the weights of the edges it is composed by.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating the categories dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary that associate evry category with his articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open('wiki-topcats-categories.txt','r')\n",
    "categorie={}\n",
    "for line in F.readlines():\n",
    "    riga=line.split(' ')\n",
    "    categoria=(riga[0].replace('Category:','').replace(';',''))\n",
    "    articles=(riga[1:-1])\n",
    "    articles.append(riga[-1].replace('\\n',''))\n",
    "    categorie[categoria]= articles\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take care of categories that contains only articles that are not in our graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must take into account all the categories that has a number of articles greater than 3500, so we clean up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories={}\n",
    "for cat in categorie:\n",
    "    if len(categorie[cat])>=3500:\n",
    "        categories[cat]=categorie[cat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove every article that is not in our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "    toremove=[]\n",
    "    for art in categories[cat]:\n",
    "        if art not in grafo:\n",
    "            toremove.append(art)\n",
    "    for art in toremove:\n",
    "        categories[cat].remove(art)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store our final categories dictionary in an external pickle file so we can reload it in need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categories.pickle', 'wb') as handle:\n",
    "    pickle.dump(categories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categories.pickle', 'rb') as handle:\n",
    "    categories = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The block ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/DijkstraDemo.gif/220px-DijkstraDemo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to solve the problem with de dijkstra algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra(graph, f, t):\n",
    "    #sorting the graph\n",
    "    g = defaultdict(list, grafo)\n",
    "    q= [(0,f)] #intializing the queque\n",
    "    seen=set() #initializing the set of seen nodes\n",
    "    distances = {f: 0} #initializing the dict of the distances\n",
    "    while q:\n",
    "        (cost,v1) = heappop(q)\n",
    "        if v1 not in seen:\n",
    "            seen.add(v1)\n",
    "            if v1 == t: return (cost)\n",
    "            if g.get(v1) is not None: \n",
    "                for v2 in g.get(v1):\n",
    "                    if v2 in seen: continue\n",
    "                    prev = distances.get(v2, None)\n",
    "                    new = cost + 1\n",
    "                    if prev is None or new < prev:\n",
    "                        distances[v2] = new\n",
    "                        heappush(q, (new, v2))\n",
    "\n",
    "    return float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catdistance(graph, catdict, cat1, cat2):\n",
    "    cat1nodes= catdict[cat1]\n",
    "    cat2nodes= catdict[cat2]\n",
    "    distances=[]\n",
    "    for node in cat1nodes:\n",
    "        for node2 in cat2nodes:\n",
    "            distances.append(dijkstra(graph=graph, f=node, t=node2))\n",
    "    return np.median(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catdistance(cat1='Japanese_rock_music_groups', cat2='Visual_kei_bands', catdict=categories, graph=grafo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works but is really slow. We want something more efficient. We can try a different approach using BFS algorithm, since the edges are not weighted.\n",
    "\n",
    "BFS should be faster since his running time is something like $\t\\mathcal{O}{\\bigl (}N+E{\\bigr )} $, while dijkstra's is ${\\displaystyle \\mathcal{O}{\\bigl (}E+N^{2}{\\bigr )}=\\mathcal{O}{\\bigl (}N^{2}{\\bigr )}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that takes a graph and a node as input and return a dictionary of his distance from every other node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, node):\n",
    "    shortestpath={}\n",
    "    visited=set()\n",
    "    queue=[node]\n",
    "    dist=0\n",
    "    while queue:\n",
    "        vicini = [] #neighbours of the nodes\n",
    "        for vertex in queue:\n",
    "            if vertex not in visited:\n",
    "                visited.add(vertex)\n",
    "                neighbours = graph[vertex]\n",
    "                vicini.extend(neighbours - visited) \n",
    "                shortestpath[vertex] = dist\n",
    "        queue=vicini\n",
    "        dist += 1\n",
    "    return shortestpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want a function that collects the bfs that starts from every node of the input category.\n",
    "\n",
    "We also want to store this list in an external file since it's a long operation and we don't want to repeat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solutiondata(graph,inp_cat, catdict):\n",
    "    inpnodes=catdict[inp_cat]\n",
    "    bfssol=[]\n",
    "    for node in tqdm(inpnodes):\n",
    "        bfssol.append(bfs(grafo, node))\n",
    "    with open('bfssol.pickle', 'wb') as handle:\n",
    "        pickle.dump(bfssol, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_of_birth_unknown\n"
     ]
    }
   ],
   "source": [
    "inputcat=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solutiondata(catdict=categories, graph=grafo, inp_cat=inputcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bfssol.pickle', 'rb') as handle:\n",
    "    bfssol = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create a dict that has as key every node of the graph and as values every shortespath from the nodes of the input category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldict = {}\n",
    "\n",
    "for diz in (bfssol):\n",
    "    for vert, value in diz.items():\n",
    "        if vert not in finaldict:\n",
    "            finaldict[vert] = [value] \n",
    "        else:\n",
    "            finaldict[vert].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finaldict.pickle', 'wb') as handle:\n",
    "    pickle.dump(finaldict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finaldict.pickle', 'rb') as handle:\n",
    "    finaldict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally build our blockranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Year_of_birth_unknown')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockranking=[(0, inputcat)]\n",
    "blockranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:57<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "lung= len(categories[inputcat])\n",
    "for cat in tqdm(categories):\n",
    "    if cat!=inputcat:\n",
    "\n",
    "        paths=[]\n",
    "        catnodes=categories[cat]\n",
    "        for node in catnodes:\n",
    "            if node in finaldict:\n",
    "                paths+=(finaldict[node])\n",
    "                imppaths= lung-len(finaldict[node])\n",
    "                paths+=([float('inf')]*imppaths)\n",
    "            else:\n",
    "                paths+=([float('inf')]*lung)\n",
    "        median=np.median(paths)\n",
    "        if median==float('inf'):\n",
    "            median=10000+paths.count(float('inf'))\n",
    "        blockranking.append(( median, cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockranking=(sorted(blockranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blockranking.pickle', 'wb') as handle:\n",
    "    pickle.dump(blockranking, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('blockranking.pickle', 'rb') as handle:\n",
    "    blockranking = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Year_of_birth_unknown'),\n",
       " (6.0, 'American_film_actors'),\n",
       " (6.0, 'American_films'),\n",
       " (6.0, 'American_television_actors'),\n",
       " (6.0, 'British_films'),\n",
       " (6.0, 'English-language_films'),\n",
       " (6.0, 'English_television_actors'),\n",
       " (7.0, 'American_Jews'),\n",
       " (7.0, 'Article_Feedback_Pilot'),\n",
       " (7.0, 'Black-and-white_films'),\n",
       " (7.0, 'Indian_films'),\n",
       " (7.0, 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies'),\n",
       " (7.0, 'People_from_New_York_City'),\n",
       " (8.0, 'Debut_albums'),\n",
       " (8.0, 'English-language_albums'),\n",
       " (8.0, 'Fellows_of_the_Royal_Society'),\n",
       " (8.0, 'Rivers_of_Romania'),\n",
       " (9.0, 'Place_of_birth_missing_(living_people)'),\n",
       " (9.0, 'Windows_games'),\n",
       " (10.0, 'American_military_personnel_of_World_War_II'),\n",
       " (10.0, 'Living_people'),\n",
       " (10.0, 'The_Football_League_players'),\n",
       " (11.0, 'English_cricketers'),\n",
       " (11.0, 'Harvard_University_alumni'),\n",
       " (13.0, 'English_footballers'),\n",
       " (4971590, 'Association_football_goalkeepers'),\n",
       " (5502511, 'Association_football_defenders'),\n",
       " (5657119, 'Major_League_Baseball_pitchers'),\n",
       " (5722046, 'Association_football_forwards'),\n",
       " (6407609, 'Year_of_death_missing'),\n",
       " (6552150, 'Year_of_birth_missing'),\n",
       " (7065574, 'Association_football_midfielders'),\n",
       " (8262170, 'Asteroids_named_for_people'),\n",
       " (20633398, 'Main_Belt_asteroids'),\n",
       " (29670880, 'Year_of_birth_missing_(living_people)')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Once you obtain the $block_{RANKING}$ vector, you want to sort the nodes in each category. The way you should sort them is explained by this example:\n",
    "\n",
    "* Suppose the categories order, given from the previous point, is $C_0, C_1, C_2$\n",
    "\n",
    "\n",
    "__[STEP1]__ Compute subgraph induced by $C_0$. For each node compute the sum of the weigths of the in-edges.\n",
    "\n",
    " <img src=\"https://latex.codecogs.com/gif.latex?score_{article_i}&space;=&space;\\sum_{i&space;\\in&space;in-edges}&space;w_i\" title=\"score_{article_i} = \\sum_{j \\in in-edges(article_i)} w_j\" />\n",
    "\n",
    "__[STEP2]__ Extend the graph to the nodes that belong to $C_1$. Thus, for each article in $C_1$ compute the score as before. __Note__ that the in-edges coming from the previous category, $C_0$, have as weights the score of the node that sends the edge.\n",
    "\n",
    "\n",
    "__[STEP3]__ Repeat Step2 up to the last category of the ranking. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an article is in more than one category, we want him only in the nearest category to the input category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [02:26<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "visti= set()\n",
    "for el in tqdm(blockranking):\n",
    "    cat=el[1]\n",
    "    nodi=[]\n",
    "    nodi+=categories[cat]\n",
    "    for node in nodi:\n",
    "        if node not in visti:\n",
    "            visti.add(node)\n",
    "        else:\n",
    "            categories[cat].remove(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categoriesclean.pickle', 'wb') as handle:\n",
    "    pickle.dump(categories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categoriesclean.pickle', 'rb') as handle:\n",
    "    categories = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.DiGraph(incoming_graph_data=grafo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[STEP1]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnodes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnodes+=categories[inputcat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=G.subgraph(nodes=subnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi={}\n",
    "ranking=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "for node in sub.in_degree:\n",
    "    nodo=node[0]\n",
    "    peso=node[1]\n",
    "    pesi[nodo]=peso\n",
    "    rank.append((peso, nodo))\n",
    "for node in sorted(rank, reverse=True):\n",
    "    ranking.append(node[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[STEP2&3]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:12<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for el in tqdm(blockranking[1:]):\n",
    "    rank=[]\n",
    "    cat=el[1]\n",
    "    catnodes=categories[cat]\n",
    "    subnodes+=catnodes\n",
    "    sub=G.subgraph(nodes=subnodes)\n",
    "    for node in catnodes:\n",
    "        peso=0\n",
    "        for pred in sub.predecessors(node):\n",
    "            if pred in pesi:\n",
    "                peso+=pesi[pred]\n",
    "            else: peso+=1\n",
    "        rank.append((peso, nodo))\n",
    "    for node in sorted(rank, reverse=True):\n",
    "        ranking.append(node[1])\n",
    "        pesi[node[1]]=node[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diogenes Lartius\n",
      "Pausanias (geographer)\n",
      "Theocritus\n",
      "Dong Zhuo\n",
      "L Bu\n",
      "Yuan Shu\n",
      "Stobaeus\n",
      "Penda of Mercia\n",
      "Stephen Dingate\n",
      "Zhang Fei\n",
      "Sextus Empiricus\n",
      "Stigand\n",
      "Ivan Alexander of Bulgaria\n",
      "Tancred of Hauteville\n",
      "Pope Nicholas II\n",
      "Sweyn II of Denmark\n",
      "Amasis II\n",
      "Horemheb\n",
      "Nefertiti\n",
      "Pope Nicholas III\n"
     ]
    }
   ],
   "source": [
    "for node in ranking[0:20]:\n",
    "    print(articles[node])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
